{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-86e0de040aac317a",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "# Лабораторная работа №1. \n",
    "\n",
    "Данная лабораторная работа состоит из нескольких блоков. В каждом блоке вам предлагается произвести некоторые манипуляции с данными и сделать некоторые выводы.\n",
    "* Задавать вопросы можно и нужно.\n",
    "* Списывать не нужно. Работы, которые были списаны обнуляются.\n",
    "* Блоки выполняются последовательно и оцениваются отдельно."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-512ba712fc0fc065",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "## Часть 1. Работа с моделями и ансамблями моделей в задачи классификации."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-b656a4266174b009",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "### 1. Чтение данных.\n",
    "Воспользуемся [датасетом](https://archive.ics.uci.edu/ml/datasets/Statlog+%28Vehicle+Silhouettes%29), в котором описываются различные автомобили. Будем решать задачу многоклассовой ($k=4$) классификации.\n",
    "Для удобства, датасет уже преобразован в удобный формат."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-eebac6bfdf73d0bc",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(846, 19) (846,)\n",
      "(549, 19) (549,) (297, 19) (297,)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "dataset = pd.read_csv('car_data.csv', delimiter=',', header=None).values\n",
    "data = dataset[:, :-1].astype(int)\n",
    "target = dataset[:, -1]\n",
    "\n",
    "print(data.shape, target.shape)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.35)\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-88b1a0f688568f2c",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "Для первичного анализа может быть полезна библиотека `pandas`. Преобразуем `train` выборку в `pd.DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>83</td>\n",
       "      <td>79</td>\n",
       "      <td>40</td>\n",
       "      <td>80</td>\n",
       "      <td>133</td>\n",
       "      <td>55</td>\n",
       "      <td>7</td>\n",
       "      <td>147</td>\n",
       "      <td>47</td>\n",
       "      <td>19</td>\n",
       "      <td>135</td>\n",
       "      <td>172</td>\n",
       "      <td>311</td>\n",
       "      <td>144</td>\n",
       "      <td>76</td>\n",
       "      <td>8</td>\n",
       "      <td>30</td>\n",
       "      <td>181</td>\n",
       "      <td>193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>212</td>\n",
       "      <td>90</td>\n",
       "      <td>41</td>\n",
       "      <td>71</td>\n",
       "      <td>169</td>\n",
       "      <td>68</td>\n",
       "      <td>7</td>\n",
       "      <td>150</td>\n",
       "      <td>44</td>\n",
       "      <td>19</td>\n",
       "      <td>138</td>\n",
       "      <td>175</td>\n",
       "      <td>336</td>\n",
       "      <td>157</td>\n",
       "      <td>71</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>192</td>\n",
       "      <td>197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>829</td>\n",
       "      <td>95</td>\n",
       "      <td>49</td>\n",
       "      <td>82</td>\n",
       "      <td>139</td>\n",
       "      <td>56</td>\n",
       "      <td>11</td>\n",
       "      <td>159</td>\n",
       "      <td>43</td>\n",
       "      <td>20</td>\n",
       "      <td>162</td>\n",
       "      <td>173</td>\n",
       "      <td>365</td>\n",
       "      <td>185</td>\n",
       "      <td>75</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>182</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>140</td>\n",
       "      <td>90</td>\n",
       "      <td>37</td>\n",
       "      <td>80</td>\n",
       "      <td>171</td>\n",
       "      <td>58</td>\n",
       "      <td>9</td>\n",
       "      <td>157</td>\n",
       "      <td>42</td>\n",
       "      <td>20</td>\n",
       "      <td>132</td>\n",
       "      <td>172</td>\n",
       "      <td>373</td>\n",
       "      <td>115</td>\n",
       "      <td>60</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>201</td>\n",
       "      <td>209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>405</td>\n",
       "      <td>88</td>\n",
       "      <td>40</td>\n",
       "      <td>73</td>\n",
       "      <td>173</td>\n",
       "      <td>68</td>\n",
       "      <td>7</td>\n",
       "      <td>150</td>\n",
       "      <td>44</td>\n",
       "      <td>19</td>\n",
       "      <td>137</td>\n",
       "      <td>174</td>\n",
       "      <td>341</td>\n",
       "      <td>151</td>\n",
       "      <td>69</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>196</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>66</td>\n",
       "      <td>81</td>\n",
       "      <td>43</td>\n",
       "      <td>68</td>\n",
       "      <td>125</td>\n",
       "      <td>57</td>\n",
       "      <td>8</td>\n",
       "      <td>149</td>\n",
       "      <td>46</td>\n",
       "      <td>19</td>\n",
       "      <td>146</td>\n",
       "      <td>169</td>\n",
       "      <td>323</td>\n",
       "      <td>172</td>\n",
       "      <td>83</td>\n",
       "      <td>6</td>\n",
       "      <td>18</td>\n",
       "      <td>179</td>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>179</td>\n",
       "      <td>89</td>\n",
       "      <td>44</td>\n",
       "      <td>70</td>\n",
       "      <td>137</td>\n",
       "      <td>58</td>\n",
       "      <td>6</td>\n",
       "      <td>136</td>\n",
       "      <td>49</td>\n",
       "      <td>18</td>\n",
       "      <td>146</td>\n",
       "      <td>168</td>\n",
       "      <td>273</td>\n",
       "      <td>166</td>\n",
       "      <td>78</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>186</td>\n",
       "      <td>187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>430</td>\n",
       "      <td>104</td>\n",
       "      <td>53</td>\n",
       "      <td>108</td>\n",
       "      <td>206</td>\n",
       "      <td>61</td>\n",
       "      <td>11</td>\n",
       "      <td>217</td>\n",
       "      <td>31</td>\n",
       "      <td>24</td>\n",
       "      <td>168</td>\n",
       "      <td>226</td>\n",
       "      <td>694</td>\n",
       "      <td>209</td>\n",
       "      <td>67</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>188</td>\n",
       "      <td>201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>219</td>\n",
       "      <td>85</td>\n",
       "      <td>39</td>\n",
       "      <td>57</td>\n",
       "      <td>126</td>\n",
       "      <td>56</td>\n",
       "      <td>6</td>\n",
       "      <td>114</td>\n",
       "      <td>58</td>\n",
       "      <td>17</td>\n",
       "      <td>135</td>\n",
       "      <td>134</td>\n",
       "      <td>195</td>\n",
       "      <td>145</td>\n",
       "      <td>64</td>\n",
       "      <td>17</td>\n",
       "      <td>7</td>\n",
       "      <td>197</td>\n",
       "      <td>202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>696</td>\n",
       "      <td>89</td>\n",
       "      <td>38</td>\n",
       "      <td>82</td>\n",
       "      <td>156</td>\n",
       "      <td>59</td>\n",
       "      <td>8</td>\n",
       "      <td>153</td>\n",
       "      <td>43</td>\n",
       "      <td>19</td>\n",
       "      <td>129</td>\n",
       "      <td>179</td>\n",
       "      <td>351</td>\n",
       "      <td>137</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>692</td>\n",
       "      <td>108</td>\n",
       "      <td>51</td>\n",
       "      <td>100</td>\n",
       "      <td>206</td>\n",
       "      <td>63</td>\n",
       "      <td>10</td>\n",
       "      <td>196</td>\n",
       "      <td>34</td>\n",
       "      <td>23</td>\n",
       "      <td>159</td>\n",
       "      <td>214</td>\n",
       "      <td>576</td>\n",
       "      <td>201</td>\n",
       "      <td>65</td>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>194</td>\n",
       "      <td>205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>308</td>\n",
       "      <td>109</td>\n",
       "      <td>51</td>\n",
       "      <td>100</td>\n",
       "      <td>197</td>\n",
       "      <td>59</td>\n",
       "      <td>10</td>\n",
       "      <td>192</td>\n",
       "      <td>34</td>\n",
       "      <td>22</td>\n",
       "      <td>161</td>\n",
       "      <td>210</td>\n",
       "      <td>553</td>\n",
       "      <td>195</td>\n",
       "      <td>64</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>196</td>\n",
       "      <td>202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>134</td>\n",
       "      <td>102</td>\n",
       "      <td>54</td>\n",
       "      <td>100</td>\n",
       "      <td>163</td>\n",
       "      <td>53</td>\n",
       "      <td>10</td>\n",
       "      <td>213</td>\n",
       "      <td>31</td>\n",
       "      <td>24</td>\n",
       "      <td>173</td>\n",
       "      <td>219</td>\n",
       "      <td>669</td>\n",
       "      <td>201</td>\n",
       "      <td>76</td>\n",
       "      <td>12</td>\n",
       "      <td>27</td>\n",
       "      <td>187</td>\n",
       "      <td>195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>716</td>\n",
       "      <td>97</td>\n",
       "      <td>41</td>\n",
       "      <td>88</td>\n",
       "      <td>184</td>\n",
       "      <td>59</td>\n",
       "      <td>9</td>\n",
       "      <td>175</td>\n",
       "      <td>38</td>\n",
       "      <td>21</td>\n",
       "      <td>140</td>\n",
       "      <td>192</td>\n",
       "      <td>459</td>\n",
       "      <td>147</td>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>196</td>\n",
       "      <td>205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>62</td>\n",
       "      <td>96</td>\n",
       "      <td>40</td>\n",
       "      <td>70</td>\n",
       "      <td>120</td>\n",
       "      <td>50</td>\n",
       "      <td>8</td>\n",
       "      <td>137</td>\n",
       "      <td>50</td>\n",
       "      <td>18</td>\n",
       "      <td>141</td>\n",
       "      <td>162</td>\n",
       "      <td>269</td>\n",
       "      <td>139</td>\n",
       "      <td>80</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>183</td>\n",
       "      <td>183</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1   2    3    4   5   6    7   8   9    10   11   12   13  14  15  \\\n",
       "0    83   79  40   80  133  55   7  147  47  19  135  172  311  144  76   8   \n",
       "1   212   90  41   71  169  68   7  150  44  19  138  175  336  157  71   3   \n",
       "2   829   95  49   82  139  56  11  159  43  20  162  173  365  185  75   7   \n",
       "3   140   90  37   80  171  58   9  157  42  20  132  172  373  115  60   3   \n",
       "4   405   88  40   73  173  68   7  150  44  19  137  174  341  151  69   2   \n",
       "5    66   81  43   68  125  57   8  149  46  19  146  169  323  172  83   6   \n",
       "6   179   89  44   70  137  58   6  136  49  18  146  168  273  166  78  10   \n",
       "7   430  104  53  108  206  61  11  217  31  24  168  226  694  209  67   0   \n",
       "8   219   85  39   57  126  56   6  114  58  17  135  134  195  145  64  17   \n",
       "9   696   89  38   82  156  59   8  153  43  19  129  179  351  137  70   1   \n",
       "10  692  108  51  100  206  63  10  196  34  23  159  214  576  201  65   7   \n",
       "11  308  109  51  100  197  59  10  192  34  22  161  210  553  195  64  14   \n",
       "12  134  102  54  100  163  53  10  213  31  24  173  219  669  201  76  12   \n",
       "13  716   97  41   88  184  59   9  175  38  21  140  192  459  147  63   1   \n",
       "14   62   96  40   70  120  50   8  137  50  18  141  162  269  139  80  10   \n",
       "\n",
       "    16   17   18  \n",
       "0   30  181  193  \n",
       "1   18  192  197  \n",
       "2   10  182  191  \n",
       "3   18  201  209  \n",
       "4   20  196  200  \n",
       "5   18  179  184  \n",
       "6    3  186  187  \n",
       "7    9  188  201  \n",
       "8    7  197  202  \n",
       "9    1  187  192  \n",
       "10  16  194  205  \n",
       "11   3  196  202  \n",
       "12  27  187  195  \n",
       "13   5  196  205  \n",
       "14  13  183  183  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_pd = pd.DataFrame(X_train)\n",
    "\n",
    "# First 15 rows of our dataset.\n",
    "X_train_pd.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-98e7d91d77d65fcf",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "Воспользовавшись методами `describe` и `info` можно получить полезную информацию о датасете."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>549.000000</td>\n",
       "      <td>549.000000</td>\n",
       "      <td>549.000000</td>\n",
       "      <td>549.000000</td>\n",
       "      <td>549.000000</td>\n",
       "      <td>549.000000</td>\n",
       "      <td>549.000000</td>\n",
       "      <td>549.000000</td>\n",
       "      <td>549.000000</td>\n",
       "      <td>549.000000</td>\n",
       "      <td>549.000000</td>\n",
       "      <td>549.000000</td>\n",
       "      <td>549.000000</td>\n",
       "      <td>549.000000</td>\n",
       "      <td>549.000000</td>\n",
       "      <td>549.000000</td>\n",
       "      <td>549.000000</td>\n",
       "      <td>549.000000</td>\n",
       "      <td>549.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>416.413479</td>\n",
       "      <td>93.566485</td>\n",
       "      <td>44.885246</td>\n",
       "      <td>81.932605</td>\n",
       "      <td>168.435337</td>\n",
       "      <td>61.471767</td>\n",
       "      <td>8.480874</td>\n",
       "      <td>168.637523</td>\n",
       "      <td>40.981785</td>\n",
       "      <td>20.575592</td>\n",
       "      <td>148.047359</td>\n",
       "      <td>188.264117</td>\n",
       "      <td>438.648452</td>\n",
       "      <td>174.979964</td>\n",
       "      <td>72.475410</td>\n",
       "      <td>6.349727</td>\n",
       "      <td>12.451730</td>\n",
       "      <td>188.808743</td>\n",
       "      <td>195.491803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>246.289994</td>\n",
       "      <td>8.162226</td>\n",
       "      <td>6.141247</td>\n",
       "      <td>16.092485</td>\n",
       "      <td>33.258251</td>\n",
       "      <td>6.886305</td>\n",
       "      <td>4.085100</td>\n",
       "      <td>32.936260</td>\n",
       "      <td>7.821202</td>\n",
       "      <td>2.558838</td>\n",
       "      <td>14.537691</td>\n",
       "      <td>30.806990</td>\n",
       "      <td>174.446932</td>\n",
       "      <td>32.261613</td>\n",
       "      <td>7.106453</td>\n",
       "      <td>4.991755</td>\n",
       "      <td>8.968108</td>\n",
       "      <td>6.110437</td>\n",
       "      <td>7.417824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>118.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>184.000000</td>\n",
       "      <td>109.000000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>176.000000</td>\n",
       "      <td>181.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>204.000000</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>147.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>138.000000</td>\n",
       "      <td>168.000000</td>\n",
       "      <td>319.000000</td>\n",
       "      <td>149.000000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>184.000000</td>\n",
       "      <td>190.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>410.000000</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>168.000000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>157.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>146.000000</td>\n",
       "      <td>179.000000</td>\n",
       "      <td>365.000000</td>\n",
       "      <td>174.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>188.000000</td>\n",
       "      <td>196.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>623.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>195.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>159.000000</td>\n",
       "      <td>217.000000</td>\n",
       "      <td>598.000000</td>\n",
       "      <td>197.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>193.000000</td>\n",
       "      <td>201.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>845.000000</td>\n",
       "      <td>119.000000</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>110.000000</td>\n",
       "      <td>306.000000</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>262.000000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>188.000000</td>\n",
       "      <td>287.000000</td>\n",
       "      <td>998.000000</td>\n",
       "      <td>268.000000</td>\n",
       "      <td>127.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>206.000000</td>\n",
       "      <td>211.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0           1           2           3           4           5   \\\n",
       "count  549.000000  549.000000  549.000000  549.000000  549.000000  549.000000   \n",
       "mean   416.413479   93.566485   44.885246   81.932605  168.435337   61.471767   \n",
       "std    246.289994    8.162226    6.141247   16.092485   33.258251    6.886305   \n",
       "min      1.000000   76.000000   33.000000   40.000000  104.000000   47.000000   \n",
       "25%    204.000000   87.000000   40.000000   70.000000  140.000000   57.000000   \n",
       "50%    410.000000   93.000000   44.000000   80.000000  168.000000   61.000000   \n",
       "75%    623.000000  100.000000   50.000000   98.000000  195.000000   65.000000   \n",
       "max    845.000000  119.000000   58.000000  110.000000  306.000000  126.000000   \n",
       "\n",
       "               6           7           8           9           10          11  \\\n",
       "count  549.000000  549.000000  549.000000  549.000000  549.000000  549.000000   \n",
       "mean     8.480874  168.637523   40.981785   20.575592  148.047359  188.264117   \n",
       "std      4.085100   32.936260    7.821202    2.558838   14.537691   30.806990   \n",
       "min      2.000000  112.000000   26.000000   17.000000  118.000000  130.000000   \n",
       "25%      6.000000  147.000000   33.000000   19.000000  138.000000  168.000000   \n",
       "50%      8.000000  157.000000   43.000000   20.000000  146.000000  179.000000   \n",
       "75%     10.000000  200.000000   46.000000   23.000000  159.000000  217.000000   \n",
       "max     52.000000  262.000000   61.000000   28.000000  188.000000  287.000000   \n",
       "\n",
       "               12          13          14          15          16          17  \\\n",
       "count  549.000000  549.000000  549.000000  549.000000  549.000000  549.000000   \n",
       "mean   438.648452  174.979964   72.475410    6.349727   12.451730  188.808743   \n",
       "std    174.446932   32.261613    7.106453    4.991755    8.968108    6.110437   \n",
       "min    184.000000  109.000000   59.000000    0.000000    0.000000  176.000000   \n",
       "25%    319.000000  149.000000   67.000000    2.000000    5.000000  184.000000   \n",
       "50%    365.000000  174.000000   72.000000    6.000000   11.000000  188.000000   \n",
       "75%    598.000000  197.000000   76.000000    9.000000   18.000000  193.000000   \n",
       "max    998.000000  268.000000  127.000000   22.000000   39.000000  206.000000   \n",
       "\n",
       "               18  \n",
       "count  549.000000  \n",
       "mean   195.491803  \n",
       "std      7.417824  \n",
       "min    181.000000  \n",
       "25%    190.000000  \n",
       "50%    196.000000  \n",
       "75%    201.000000  \n",
       "max    211.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_pd.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 549 entries, 0 to 548\n",
      "Data columns (total 19 columns):\n",
      "0     549 non-null int64\n",
      "1     549 non-null int64\n",
      "2     549 non-null int64\n",
      "3     549 non-null int64\n",
      "4     549 non-null int64\n",
      "5     549 non-null int64\n",
      "6     549 non-null int64\n",
      "7     549 non-null int64\n",
      "8     549 non-null int64\n",
      "9     549 non-null int64\n",
      "10    549 non-null int64\n",
      "11    549 non-null int64\n",
      "12    549 non-null int64\n",
      "13    549 non-null int64\n",
      "14    549 non-null int64\n",
      "15    549 non-null int64\n",
      "16    549 non-null int64\n",
      "17    549 non-null int64\n",
      "18    549 non-null int64\n",
      "dtypes: int64(19)\n",
      "memory usage: 81.6 KB\n"
     ]
    }
   ],
   "source": [
    "X_train_pd.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-be844269be69c387",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "### 2. Работа с данными, построение модели, анализ ошибки.\n",
    "Выполните следующие манипуляции с данными:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.0. Предобработка данных.\n",
    "* Произведите необходимые (по вашему мнению) манипуляции с данными и объясните их."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-a1514aa189a49fca",
     "locked": false,
     "points": 15,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1. Базовая логистическая регрессия.\n",
    "* Подберите оптимальные параметры логистической регресии с помощью кросс-валидации на train-датасете (е переусердствуйте с подбором, в данной работе не стоит задача найти самую оптимальную модель. Небольшого grid/random search'а хватит).\n",
    "\n",
    "* Постройте график ROC-кривой для данного классификатора (`sklearn.metrics.roc_curve`), оцените точность классификации и f1-score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-1dd5ad5d0845cbbb",
     "locked": false,
     "points": 5,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression results for original data:\n",
      "{'C': 0.23, 'penalty': 'l2'}\n",
      "accuracy_test =  0.797979797979798\n",
      "f1_score_test =  0.7979797979797979\n"
     ]
    }
   ],
   "source": [
    "### YOUR CODE HERE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "print ('Logistic regression results for original data:')\n",
    "lr_clf = LogisticRegression()\n",
    "parametrs = {'C': np.linspace(0.01, 1, 10),'penalty': ['l1','l2']} # какие?\n",
    "clf = GridSearchCV(lr_clf, parametrs, scoring='accuracy', cv=5, n_jobs=-1)\n",
    "clf.fit(X_train, y_train)\n",
    "C = clf.best_params_['C']\n",
    "penalty = clf.best_params_['penalty']\n",
    "print (clf.best_params_)\n",
    "\n",
    "best_lr_clf = LogisticRegression(penalty=penalty, C=C)\n",
    "best_lr_clf.fit(X_train, y_train)\n",
    "y_predict = best_lr_clf.predict(X_test)\n",
    "print(classification_report(y_test, y_predict, target_names=target_names))\n",
    "print(\"accuracy_test = \", accuracy_score(y_test,y_predict))\n",
    "print(\"f1_score_test = \", f1_score(y_test,y_predict,average='micro')) # read about average\n",
    "\n",
    "# ROC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2. Зависимость объясненной дисперсии от числа главных компонент.\n",
    "Воспользуемся методом главных компонент (PCA). \n",
    "\n",
    "Примените его к train-части данных.\n",
    "Постройте график зависимости объясненной дисперсии (explained variance ratio) от количества главных компонент."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-c6c614740bce090e",
     "locked": false,
     "points": 10,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "### YOUR CODE HERE\n",
    "from sklearn import decomposition\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pca = decomposition.PCA(n_components=18)\n",
    "pca.fit(X_train)\n",
    "eva = pca.explained_variance_ratio_ # Percentage of variance explained by each of the selected components.\n",
    "    \n",
    "plt.plot(range(1,19), eva)\n",
    "plt.show()\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html\n",
    "# http://rcs.chemometrics.ru/Tutorials/pca.htm\n",
    "# Метод главных компонент – это итерационная процедура, в которой новые компоненты добавляются последовательно, \n",
    "# одна за другой. Важно знать, когда остановить этот процесс, т.е. как определить правильное число главных компонент,\n",
    "# A. Если это число слишком мало, то описание данных будет не полным. С другой стороны, избыточное число главных\n",
    "# компонент приводит к переоценке, т.е. к ситуации, когда моделируется шум, а не содержательная информация."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-0c1fe666f52fe53c",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "#### 2.3. Преобразование с помощью PCA.\n",
    "Выберите определенное число компонент. Кратко опишите, чем обусловлен ваш выбор.\n",
    "\n",
    "Используя эти главные компоненты, преобразуйте train и test выборки (используя методы `fit` и `transform`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-96ab18d96473ef71",
     "locked": false,
     "points": 5,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "### YOUR CODE HERE\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html\n",
    "\n",
    "best_components = 16\n",
    "pca = decomposition.PCA(n_components=best_components)\n",
    "pca.fit(X_train)\n",
    "X_train_PCA = pca.transform(X_train)\n",
    "pca.fit(X_test)\n",
    "X_test_PCA = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-d28b58a35c94e988",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "#### 2.4. Логистическая регрессия над преобразованными данными.\n",
    "* Подберите оптимальные параметры логистической регресии с помощью кросс-валидации на преобразованном train-датасете.\n",
    "\n",
    "* Постройте график ROC-кривой для полученных классификаторов, оцените точность классификации и f1-score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-12d53ea45258fa82",
     "locked": false,
     "points": 5,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression results for transformed data:\n",
      "{'C': 0.78, 'penalty': 'l1'}\n",
      "accuracy_test =  0.5353535353535354\n",
      "f1_score_test =  0.5353535353535354\n"
     ]
    }
   ],
   "source": [
    "### YOUR CODE HERE\n",
    "#  выглядит как 2.1\n",
    "print ('Logistic regression results for transformed data:')\n",
    "lr_clf = LogisticRegression()\n",
    "parametrs = {'C': np.linspace(0.01, 1, 10),'penalty': ['l1','l2']} # какие?\n",
    "clf = GridSearchCV(lr_clf, parametrs, scoring='accuracy', cv=5, n_jobs=-1)\n",
    "clf.fit(X_train_PCA, y_train)\n",
    "C = clf.best_params_['C']\n",
    "penalty = clf.best_params_['penalty']\n",
    "print (clf.best_params_)\n",
    "\n",
    "best_lr_clf = LogisticRegression(penalty=penalty, C=C)\n",
    "best_lr_clf.fit(X_train_PCA, y_train)\n",
    "y_predict = best_lr_clf.predict(X_test_PCA)\n",
    "print(\"accuracy_test = \", accuracy_score(y_test,y_predict))\n",
    "print(\"f1_score_test = \", f1_score(y_test,y_predict,average='micro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-4fbf16c64076e139",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "#### 2.5. Решающее дерево.\n",
    "Рассмотрим поведение решающего дерева на исходных и преобразованных данных. Будем варьировать лишь один параметр - максимальную глубину дерева. \n",
    "\n",
    "* С помощью кросс-валидации подберите оптимальный параметр `max_depth` и оцените на исходных и преобразованных данных те же метрики, что и выше."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-748ed20b51c67fab",
     "locked": false,
     "points": 15,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision tree results for original data:\n",
      "{'max_depth': 3}\n",
      "accuracy_test =  0.632996632996633\n",
      "f1_score_test =  0.632996632996633\n",
      "\n",
      "Decision tree results for transformed data:\n",
      "{'max_depth': 4}\n",
      "accuracy_test =  0.5589225589225589\n",
      "f1_score_test =  0.5589225589225589\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# YOUR CODE HERE\n",
    "print ('Decision tree results for original data:')\n",
    "dt_clf = DecisionTreeClassifier()\n",
    "parametrs = {'max_depth': range(1,5)} # какие?\n",
    "clf = GridSearchCV(dt_clf, parametrs, scoring='accuracy', cv=5, n_jobs=-1)\n",
    "clf.fit(X_train, y_train)\n",
    "max_depth_orig = clf.best_params_['max_depth']\n",
    "print (clf.best_params_)\n",
    "\n",
    "best_dt_clf_orig = DecisionTreeClassifier(max_depth=max_depth_orig)\n",
    "best_dt_clf_orig.fit(X_train, y_train)\n",
    "y_predict = best_dt_clf_orig.predict(X_test)\n",
    "print(\"accuracy_test = \", accuracy_score(y_test,y_predict))\n",
    "print(\"f1_score_test = \", f1_score(y_test,y_predict,average='micro'))\n",
    "\n",
    "# 'на исходных и преобразованных данных' =>\n",
    "print ('\\nDecision tree results for transformed data:')\n",
    "dt_clf = DecisionTreeClassifier()\n",
    "parametrs = {'max_depth': range(1,5)} # какие?\n",
    "clf = GridSearchCV(dt_clf, parametrs, scoring='accuracy', cv=5, n_jobs=-1)\n",
    "clf.fit(X_train_PCA, y_train)\n",
    "max_depth_modif = clf.best_params_['max_depth']\n",
    "print (clf.best_params_)\n",
    "\n",
    "best_dt_clf_modif = DecisionTreeClassifier(max_depth=max_depth_modif)\n",
    "best_dt_clf_modif.fit(X_train_PCA, y_train)\n",
    "y_predict = best_dt_clf_modif.predict(X_test_PCA)\n",
    "print(\"accuracy_test = \", accuracy_score(y_test,y_predict))\n",
    "print(\"f1_score_test = \", f1_score(y_test,y_predict,average='micro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-9eadd4d8a03ae67a",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "#### 2.6. Bagging.\n",
    "Перейдем к ансамблям. \n",
    "\n",
    "Для построения ансамбля воспользуемся Bagging'ом с числом алгоритмов от 2 до 50. В качестве первого семейства базовых алгоримтов будем использовать линейные модели (т.е. логистическую регрессию), в качестве второго - решающие деревья. \n",
    "\n",
    "*Пояснение: Будем строить ансамбль только из моделей из одного семейства, т.е. логистическая регрессия не смешивается с решающими деревьями.*\n",
    "\n",
    "Для этого можно сгенерировать с помощью метода bootstrap 50 подвыборок из `train` выборки (того же размера, что и исходная), обучить логистическую регрессию и решающее дерево с оптимальными параметрами из предыдущего пункта на каждой из подвыборок и затем усреднить предсказания k моделей.\n",
    "\n",
    "*Hint: в sklearn может найтись подходящая функция, которая облегчит вам реализацию данного пункта.*\n",
    "\n",
    "* Постройте график качества классификации и f1-score на `train` и `test` датасетах в зависимости от числа алгоритмов, вошедших в ансамбль.\n",
    "\n",
    "* Проанализируйте график. Какое количество моделей стоит использовать? Как вы думаете, являются ли параметры решающего дерева, подобранные в предыдущем пункте оптимальными в данном случае?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-8fc95a2b206bdae1",
     "locked": false,
     "points": 35,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'best_dt_clf_orig' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-77-d0f7d51926a8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0msubsets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mbest_dt_clf_orig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0my_predict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbest_dt_clf_orig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'best_dt_clf_orig' is not defined"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "from sklearn.utils import resample\n",
    "\n",
    "subsets = []\n",
    "for i in range(0,50):\n",
    "    subsets.append(resample(X_train, replace=True, n_samples=len(X_train), random_state=i))\n",
    "\n",
    "best_dt_clf_orig.fit(X_train, y_train)\n",
    "y_predict = best_dt_clf_orig.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-241b7691ab44cbfb",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "## 2.7. Random Forest.\n",
    "Теперь воспользуйтесь `sklearn`-реализацией алгоритма Random Forest. \n",
    "\n",
    "* Постройте аналогичные графики для него (изменяя число деревьев от 1 до 50). Остальные параметры можно оставить по умолчанию.\n",
    "\n",
    "* Проанализируйте полученные результаты. Каким получилось оптимальное число деревьев. Как оно соотносится с оптимальным числом деревьев и линейных моделей в bagging'е из предыдущего пункта?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-888755d0f3d91620",
     "locked": false,
     "points": 15,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# YOUR CODE HERE\n",
    "rf_clf = RandomForestClassifier(n_estimators=50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-99191c0852538d4d",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "#### 2.8. Кривая обучения.\n",
    "* Поделите обучающую выборку на 10 примерно равных частей. Обучите логистическую регрессию (с оптимальными параметрами), решающее дерево (аналогично), бэггинг над логистическими регрессиями и решающими деревьями (с выбранными параметрами) и RandomForest (из предыдущего пункта) на одной, двух, трех и т.д. частях.\n",
    "\n",
    "* Постройти график f1-score и accuracy на `train` и `test` датасетах в зависимости от размера обучающей выборки.\n",
    "\n",
    "* Проанализируйте полученный график. Можно ли сделать из него какие-либо выводы? Если да - кратко опишите их."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-e39bc7e7dff61ff9",
     "locked": false,
     "points": 15,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-71bd7c04299937c1",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "Вторая часть задания про SVM ждет вас в соседнем ноутбуке."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
